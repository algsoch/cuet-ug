{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885ecfb5",
   "metadata": {},
   "source": [
    "# DU Admission Analyzer - Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the DU Admission Analyzer to extract, clean, analyze, and export Delhi University admission data from PDFs.\n",
    "\n",
    "## Features\n",
    "- ðŸ“„ **PDF Extraction**: Extract tables from DU admission PDFs\n",
    "- ðŸ§¹ **Data Cleaning**: Handle split rows, merge data, fix column alignment\n",
    "- ðŸ“Š **Analytics**: Generate comprehensive analytics and insights\n",
    "- ðŸ“¤ **Excel Export**: Export to formatted Excel with multiple sheets\n",
    "- ðŸ”„ **Batch Processing**: Process multiple PDFs at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad591470",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas tabula-py openpyxl xlsxwriter requests matplotlib seaborn pdfplumber PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac065e9d",
   "metadata": {},
   "source": [
    "## Import and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('src')\n",
    "\n",
    "# Import our modules\n",
    "from src.pipeline import process_admission_pdf, DUAdmissionPipeline\n",
    "from src.pdf_extractor import extract_pdf\n",
    "from src.data_cleaner import clean_data\n",
    "from src.analytics import generate_analytics_summary\n",
    "from src.excel_exporter import export_to_excel\n",
    "\n",
    "print(\"âœ… All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c0d63",
   "metadata": {},
   "source": [
    "## Quick Start - Process a Single PDF\n",
    "\n",
    "Let's process the example PDF from the DU website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example PDF URL from DU website\n",
    "pdf_url = \"https://admission.uod.ac.in/userfiles/downloads/25082025_VacantSeats_UG_Spot_Round.pdf\"\n",
    "\n",
    "# Process the PDF through the complete pipeline\n",
    "print(\"ðŸš€ Starting PDF processing...\")\n",
    "results = process_admission_pdf(pdf_url, output_dir=\"outputs\")\n",
    "\n",
    "if results['success']:\n",
    "    print(f\"\\nâœ… Processing successful!\")\n",
    "    print(f\"ðŸ“Š Data Shape: {results['data_shape']}\")\n",
    "    print(f\"ðŸ“ Excel Export: {results['files']['excel']}\")\n",
    "    print(f\"ðŸ“„ CSV Backup: {results['files']['csv']}\")\n",
    "else:\n",
    "    print(f\"âŒ Processing failed: {results['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302f002",
   "metadata": {},
   "source": [
    "## View Key Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results['success']:\n",
    "    analytics = results['analytics']\n",
    "    \n",
    "    print(\"ðŸ“Š OVERVIEW:\")\n",
    "    overview = analytics['overview']\n",
    "    for key, value in overview.items():\n",
    "        print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    print(\"\\nðŸ” KEY INSIGHTS:\")\n",
    "    for i, insight in enumerate(analytics['insights'][:5], 1):\n",
    "        print(f\"   {i}. {insight}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ CATEGORY TOTALS:\")\n",
    "    totals = analytics['totals']\n",
    "    for category, total in totals.items():\n",
    "        if category != 'grand_total':\n",
    "            print(f\"   {category}: {total:,} seats\")\n",
    "    print(f\"   GRAND TOTAL: {totals['grand_total']:,} seats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c70449",
   "metadata": {},
   "source": [
    "## Step-by-Step Processing (Advanced)\n",
    "\n",
    "For more control, you can process each step individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bcb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = DUAdmissionPipeline(\"outputs\")\n",
    "\n",
    "# Step 1: Extract raw data\n",
    "print(\"ðŸ“„ Step 1: Extracting data from PDF...\")\n",
    "raw_data = extract_pdf(pdf_url)\n",
    "print(f\"Extracted {len(raw_data)} rows, {len(raw_data.columns)} columns\")\n",
    "print(\"\\nFirst few rows of raw data:\")\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb53170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean the data\n",
    "print(\"ðŸ§¹ Step 2: Cleaning data...\")\n",
    "clean_df = clean_data(raw_data)\n",
    "print(f\"Cleaned data: {len(clean_df)} rows, {len(clean_df.columns)} columns\")\n",
    "print(\"\\nFirst few rows of clean data:\")\n",
    "print(clean_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826623de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate analytics\n",
    "print(\"ðŸ“Š Step 3: Generating analytics...\")\n",
    "analytics = generate_analytics_summary(clean_df)\n",
    "\n",
    "# Display college-wise analysis (top 10)\n",
    "print(\"\\nTop 10 Colleges by Total Seats:\")\n",
    "college_analysis = analytics['college_wise']\n",
    "print(college_analysis.head(10)[['Total_Seats', 'Program_Count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d559daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display program-wise analysis (top 10)\n",
    "print(\"Top 10 Programs by Total Seats:\")\n",
    "program_analysis = analytics['program_wise']\n",
    "print(program_analysis.head(10)[['Total_Seats', 'College_Count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ceb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display category-wise analysis\n",
    "print(\"Category-wise Analysis:\")\n",
    "category_analysis = analytics['category_wise']\n",
    "print(category_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fafb4",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09808fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "from src.analytics import AdmissionAnalytics\n",
    "\n",
    "analytics_obj = AdmissionAnalytics(clean_df)\n",
    "visualizations = analytics_obj.create_visualizations()\n",
    "\n",
    "# Display category distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_data = analytics['category_wise']\n",
    "plt.pie(category_data['Total_Seats'], labels=category_data['Category'], autopct='%1.1f%%')\n",
    "plt.title('Seat Distribution by Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top colleges bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_colleges = college_analysis.head(10)\n",
    "plt.barh(range(len(top_colleges)), top_colleges['Total_Seats'])\n",
    "plt.yticks(range(len(top_colleges)), [name[:40] + '...' if len(name) > 40 else name for name in top_colleges.index])\n",
    "plt.xlabel('Total Seats')\n",
    "plt.title('Top 10 Colleges by Total Seats')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df0fb0",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Export to Excel\n",
    "print(\"ðŸ“¤ Step 4: Exporting to Excel...\")\n",
    "excel_path = export_to_excel(clean_df, \"demo_analysis.xlsx\", \"outputs\")\n",
    "print(f\"âœ… Exported to: {excel_path}\")\n",
    "\n",
    "# Also save as CSV\n",
    "csv_path = \"outputs/demo_clean_data.csv\"\n",
    "clean_df.to_csv(csv_path, index=False)\n",
    "print(f\"ðŸ“„ CSV saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fc9fa",
   "metadata": {},
   "source": [
    "## Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284291ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality\n",
    "print(\"ðŸ” DATA QUALITY REPORT:\")\n",
    "print(f\"Total rows: {len(clean_df)}\")\n",
    "print(f\"Total columns: {len(clean_df.columns)}\")\n",
    "print(f\"\\nColumns: {list(clean_df.columns)}\")\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "missing = clean_df.isnull().sum()\n",
    "for col, count in missing.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {col}: {count}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "for col, dtype in clean_df.dtypes.items():\n",
    "    print(f\"   {col}: {dtype}\")\n",
    "\n",
    "# Check numeric columns\n",
    "numeric_cols = ['UR', 'OBC', 'SC', 'ST', 'EWS', 'SIKH', 'PwBD']\n",
    "print(\"\\nNumeric column statistics:\")\n",
    "for col in numeric_cols:\n",
    "    if col in clean_df.columns:\n",
    "        print(f\"   {col}: min={clean_df[col].min()}, max={clean_df[col].max()}, sum={clean_df[col].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beff436",
   "metadata": {},
   "source": [
    "## Sample Data Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of the clean data\n",
    "print(\"ðŸ“‹ SAMPLE OF CLEAN DATA:\")\n",
    "print(clean_df.head(10))\n",
    "\n",
    "print(\"\\nðŸ“Š SUMMARY STATISTICS:\")\n",
    "print(clean_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27058b25",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrated the complete DU Admission Analyzer pipeline. You can now:\n",
    "\n",
    "1. **Process different PDFs**: Change the `pdf_url` to process other spot round PDFs\n",
    "2. **Customize analytics**: Modify the analytics functions in `src/analytics.py`\n",
    "3. **Batch processing**: Use the batch processing feature for multiple PDFs\n",
    "4. **FastAPI integration**: The modular design makes it easy to integrate into a web API\n",
    "5. **Custom visualizations**: Add more charts and graphs in the analytics module\n",
    "\n",
    "### For FastAPI Integration:\n",
    "```python\n",
    "from fastapi import FastAPI, UploadFile\n",
    "from src.pipeline import process_admission_pdf\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/upload\")\n",
    "async def upload_pdf(file: UploadFile):\n",
    "    # Save uploaded file temporarily\n",
    "    # Process with pipeline\n",
    "    results = process_admission_pdf(temp_file_path)\n",
    "    return results\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
